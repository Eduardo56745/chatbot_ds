{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55acad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3c2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extraer_texto_de_pdfs(carpeta):\n",
    "    textos = {}\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        if archivo.endswith(\".pdf\"):\n",
    "            ruta_pdf = os.path.join(carpeta, archivo)\n",
    "            doc = fitz.open(ruta_pdf)\n",
    "            texto = \"\"\n",
    "            for pagina in doc:\n",
    "                texto += pagina.get_text()\n",
    "            textos[archivo] = texto\n",
    "    return textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb4372e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto extraído de 1._fundamentos_de_hojas_de_clculo.pdf:\n",
      "1. Fundamentos de hojas de cálculo\n",
      "1\n",
      "1. Fundamentos de hojas de \n",
      "cálculo\n",
      "1.1 Cómo acceder a los dato...\n",
      "\n",
      "Texto extraído de 1_Resumen_del_captulo_Lectura_y_visualizacin_de_datos.pdf:\n",
      "Resumen del capítulo: Lectura y visualización de datos\n",
      "1\n",
      "Resumen del capítulo: Lectura y \n",
      "visualizac...\n",
      "\n",
      "Texto extraído de 2.Resumen_del_captulo_Teora_de_la_probabilidad.pdf:\n",
      "Resumen del capítulo: Teoría de la probabilidad\n",
      "1\n",
      "Resumen del capítulo: Teoría de \n",
      "la probabilidad\n",
      "E...\n",
      "\n",
      "Texto extraído de 2._limpieza_de_datos_y_preprocesamiento.pdf:\n",
      "2. Limpieza de datos y preprocesamiento\n",
      "1\n",
      "2. Limpieza de datos y \n",
      "preprocesamiento\n",
      "2.1 Comprensión d...\n",
      "\n",
      "Texto extraído de 2_Hoja_informativa_Estadstica_descriptiva.pdf:\n",
      "Hoja informativa: Estadística descriptiva\n",
      "1\n",
      "Hoja informativa: Estadística \n",
      "descriptiva\n",
      "Práctica\n",
      "# Cr...\n",
      "\n",
      "Texto extraído de 2_Resumen_del_captulo_Estadstica_descriptiva.pdf:\n",
      "Resumen del capítulo: Estadística descriptiva\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Estadística descriptiva\n",
      "Varia...\n",
      "\n",
      "Texto extraído de 3.Gua_rpida_para_valores_ausentes.pdf:\n",
      "Guía rápida para valores ausentes\n",
      "1\n",
      "Guía rápida para valores \n",
      "ausentes\n",
      "Cuándo completar valores ause...\n",
      "\n",
      "Texto extraído de 3._tablas_dinmicas.pdf:\n",
      "3. Tablas dinámicas\n",
      "1\n",
      "3. Tablas dinámicas\n",
      "3.1 ¿Qué es una tabla dinámica?\n",
      "Una tabla dinámica es una ...\n",
      "\n",
      "Texto extraído de 3_Hoja_informativa_Trabajar_con_valores_ausentes_y_duplicados.pdf:\n",
      "Hoja informativa: Trabajar con valores ausentes y duplicados\n",
      "1\n",
      "Hoja informativa: Trabajar con \n",
      "valor...\n",
      "\n",
      "Texto extraído de 3_Resumen_del_captulo_Trabajar_con_valores_ausentes_y_duplicados.pdf:\n",
      "Resumen del capítulo: Trabajar con valores ausentes y duplicados\n",
      "1\n",
      "Resumen del capítulo: Trabajar \n",
      "c...\n",
      "\n",
      "Texto extraído de 4.Hoja_informativa_Prueba_de_hiptesis.pdf:\n",
      "Hoja informativa: Prueba de hipótesis\n",
      "1\n",
      "Hoja informativa: Prueba de \n",
      "hipótesis\n",
      "Práctica\n",
      "# probar una...\n",
      "\n",
      "Texto extraído de 4._grficas_y_diagramas.pdf:\n",
      "4. Gráficas y diagramas\n",
      "1\n",
      "4. Gráficas y diagramas\n",
      "4.1 Gráficos básicos en Google Sheets\n",
      "1. Gráficos ...\n",
      "\n",
      "Texto extraído de 4_Hoja_informativa_Filtrado_por_mltiples_condiciones.pdf:\n",
      "Hoja informativa: Filtrado por múltiples condiciones\n",
      "1\n",
      "Hoja informativa: Filtrado por \n",
      "múltiples con...\n",
      "\n",
      "Texto extraído de 4_Resumen_del_capítulo_Filtrado_de_datos.pdf:\n",
      "Resumen del capítulo: Filtrado de datos\n",
      "1\n",
      "Resumen del capítulo: Filtrado de datos\n",
      "Filtrado personali...\n",
      "\n",
      "Texto extraído de 4_Resumen_del_captulo_Prueba_de_hiptesis.pdf:\n",
      "Resumen del capítulo: Prueba de hipótesis\n",
      "1\n",
      "Resumen del capítulo: Prueba de \n",
      "hipótesis\n",
      "Muestreo alea...\n",
      "\n",
      "Texto extraído de 4_Resumen_loc_vs._iloc.pdf:\n",
      "Resumen: loc[] vs. iloc[]\n",
      "1\n",
      "Resumen: loc[] vs. iloc[]\n",
      "Los objetos Series y DataFrame en pandas siemp...\n",
      "\n",
      "Texto extraído de 6_Resumen_del_captulo_Visualizacin_de_los_datos.pdf:\n",
      "Resumen del capítulo: Visualización de los datos\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Visualización de los datos...\n",
      "\n",
      "Texto extraído de 7_Resumen_del_captulo_Tipos_de_datos.pdf:\n",
      "Resumen del capítulo: Tipos de datos\n",
      "1\n",
      "Resumen del capítulo: Tipos de \n",
      "datos\n",
      "Variables categóricas y...\n",
      "\n",
      "Texto extraído de 9_Resumen_del_captulo_Transformacin_de_datos.pdf:\n",
      "Resumen del capítulo: Transformación de datos\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Transformación de datos\n",
      "Agrup...\n",
      "\n",
      "Texto extraído de DS_14 Sprint_Resumen_del_captulo_Representaciones_del_lenguaje.pdf:\n",
      "Resumen del capítulo: Representaciones del lenguaje\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Representaciones del le...\n",
      "\n",
      "Texto extraído de DS_ES_9_Sprint_Hoja_informativa_Recopilacin_de_datos.pdf:\n",
      "Hoja informativa: Recopilación de datos\n",
      "1\n",
      "Hoja informativa: Recopilación \n",
      "de datos\n",
      "Práctica\n",
      "# Valida...\n",
      "\n",
      "Texto extraído de DS_ES_9_Sprint_Resumen_del_captulo_Recopilacin_de_datos.pdf:\n",
      "Resumen del capítulo: Recopilación de datos\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Recopilación de datos\n",
      "Fuentes d...\n",
      "\n",
      "Texto extraído de Eduardo Ortega Torres_DS.pdf:\n",
      "#0001008\n",
      "17/04/2025\n",
      "Eduardo Ortega\n",
      "Torres   \n",
      "...\n",
      "\n",
      "Texto extraído de ESP_Hoja_informativa_Representaciones_del_lenguaje.pdf:\n",
      "Hoja informativa: Representaciones del lenguaje\n",
      "1\n",
      "Hoja informativa: \n",
      "Representaciones del lenguaje\n",
      "P...\n",
      "\n",
      "Texto extraído de ESP_Hoja_informativa_Vectorizacin_de_textos.pdf:\n",
      "Hoja informativa: Vectorización de textos\n",
      "1\n",
      "Hoja informativa: Vectorización \n",
      "de textos\n",
      "Práctica\n",
      "# NL...\n",
      "\n",
      "Texto extraído de ESP_Resumen_del_captulo_Vectorizacin_de_textos.pdf:\n",
      "Resumen del capítulo: Vectorización de textos\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Vectorización de textos\n",
      "Lemat...\n",
      "\n",
      "Texto extraído de ES_DS 13 Sprint_Resumen_del_captulo_Anlisis_de_series_temporales.pdf:\n",
      "Resumen del capítulo: Análisis de series temporales\n",
      "1\n",
      "Resumen del capítulo: Análisis \n",
      "de series temp...\n",
      "\n",
      "Texto extraído de ES_Resumen_del_captulo_Mtricas_de_negocios.pdf:\n",
      "Resumen del capítulo: Métricas de negocios\n",
      "1\n",
      "Resumen del capítulo: Métricas \n",
      "de negocios\n",
      "Ingreso, co...\n",
      "\n",
      "Texto extraído de Hoja_informativa_Anlisis_de_series_temporales.pdf:\n",
      "Hoja informativa: Análisis de series temporales\n",
      "1\n",
      "Hoja informativa: Análisis de \n",
      "series temporales\n",
      "P...\n",
      "\n",
      "Texto extraído de Hoja_informativa_clasificacin_desequilibrada_ES.pdf:\n",
      "Hoja informativa: clasificación desequilibrada\n",
      "1\n",
      "Hoja informativa: clasificación \n",
      "desequilibrada\n",
      "Prá...\n",
      "\n",
      "Texto extraído de Hoja_informativa_Distancia_entre_vectores.pdf:\n",
      "Hoja informativa: Distancia entre vectores\n",
      "1\n",
      "Hoja informativa: Distancia entre \n",
      "vectores\n",
      "Práctica\n",
      "# ...\n",
      "\n",
      "Texto extraído de Hoja_informativa_Pronstico_de_series_temporales_ESP.pdf:\n",
      "Hoja informativa: Pronóstico de series temporales\n",
      "1\n",
      "Hoja informativa: Pronóstico de \n",
      "series temporal...\n",
      "\n",
      "Texto extraído de Hoja_informativa_Recuperacin_de_datos_de_recursos_en_lnea.pdf:\n",
      "Hoja informativa: Recuperación de datos de recursos en línea\n",
      "1\n",
      "Hoja informativa: Recuperación \n",
      "de da...\n",
      "\n",
      "Texto extraído de Hoja_informativa_Redes_neuronales_convolucionales_esp.pdf:\n",
      "Hoja informativa: Redes neuronales convolucionales\n",
      "1\n",
      "Hoja informativa: Redes \n",
      "neuronales convolucion...\n",
      "\n",
      "Texto extraído de Hoja_informativa_Redes_totalmente_conectadas_esp.pdf:\n",
      "Hoja informativa: Redes totalmente conectadas\n",
      "1\n",
      "Hoja informativa: Redes \n",
      "totalmente conectadas\n",
      "Práct...\n",
      "\n",
      "Texto extraído de Hoja_informativa_SQL_como_herramienta_para_trabajar_con_datos.pdf:\n",
      "Hoja informativa: SQL como herramienta para trabajar con datos\n",
      "1\n",
      "Hoja informativa: SQL como \n",
      "herrami...\n",
      "\n",
      "Texto extraído de moved_DS_11_sprint_Hoja_informativa_Matrices_y_operaciones_matriciales_id.pdf:\n",
      "Hoja informativa: Matrices y operaciones matriciales\n",
      "1\n",
      "Hoja informativa: Matrices y \n",
      "operaciones mat...\n",
      "\n",
      "Texto extraído de moved_DS_11_sprint_Hoja_informativa_Regresin_lineal_desde_adentro_esp.pdf:\n",
      "Hoja informativa: Regresión lineal desde adentro\n",
      "1\n",
      "Hoja informativa: Regresión \n",
      "lineal desde adentro...\n",
      "\n",
      "Texto extraído de moved_DS_11_sprint_Hoja_informativa_Vectores_y_operaciones_vectoriales_esp.pdf:\n",
      "Hoja informativa: Vectores y operaciones vectoriales\n",
      "1\n",
      "Hoja informativa: Vectores y \n",
      "operaciones vec...\n",
      "\n",
      "Texto extraído de moved_Hoja_informaiva_Mejora_del_modelo.pdf:\n",
      "Hoja informaiva: Mejora del modelo\n",
      "1\n",
      "Hoja informaiva: Mejora del modelo\n",
      "Práctica\n",
      "# División de datos...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Anlisis_de_algoritmos_DS_Sprint_12_esp.pdf:\n",
      "Hoja informativa: Análisis de algoritmos\n",
      "1\n",
      "Hoja informativa: Análisis de \n",
      "algoritmos\n",
      "El tiempo de ej...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Calidad_del_modelo_1.pdf:\n",
      "Hoja informativa: Calidad del modelo\n",
      "1\n",
      "Hoja informativa: Calidad del \n",
      "modelo\n",
      "Práctica\n",
      "# Especificar ...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Descenso_de_gradiente_DS_Sprint_12_Esp.pdf:\n",
      "Hoja informativa: Descenso de gradiente\n",
      "1\n",
      "Hoja informativa: Descenso de \n",
      "gradiente\n",
      "Práctica\n",
      "import n...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Entrenamiento_del_descenso_de_gradiente_DS_Sprint_12_ESP.pdf:\n",
      "Hoja informativa: Entrenamiento del descenso de gradiente\n",
      "1\n",
      "Hoja informativa: Entrenamiento \n",
      "del des...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Funciones_avanzadas_de_SQL_para_analistas.pdf:\n",
      "Hoja informativa: Funciones avanzadas de SQL para analistas\n",
      "1\n",
      "Hoja informativa: Funciones \n",
      "avanzadas...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Implementacin_de_una_nueva_funcionalidad.pdf:\n",
      "Hoja informativa: Implementación de una nueva funcionalidad\n",
      "1\n",
      "Hoja informativa: \n",
      "Implementación de u...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_mtricas_clasificacin.pdf:\n",
      "Hoja informativa: métricas de clasificación\n",
      "1\n",
      "Hoja informativa: métricas de \n",
      "clasificación\n",
      "Práctica\n",
      "...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_mtricas_de_regresin.pdf:\n",
      "Hoja informativa: métricas de regresión\n",
      "1\n",
      "Hoja informativa: métricas de \n",
      "regresión\n",
      "Práctica\n",
      "# Para c...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Pasar_a_la_regresin.pdf:\n",
      "Hoja informativa: Pasar a la regresión\n",
      "1\n",
      "Hoja informativa: Pasar a la regresión\n",
      "Práctica\n",
      "# Calcular ...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Potenciacin_del_gradiente_DS_Sprint12_ESP.pdf:\n",
      "Hoja informativa: Potenciación del gradiente\n",
      "1\n",
      "Hoja informativa: Potenciación \n",
      "del gradiente\n",
      "Práctic...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_preparacin_de_caractersticas_Takeaway_sheet_Feature_Preparation_esp.pdf:\n",
      "Hoja informativa: preparación de características\n",
      "1\n",
      "Hoja informativa: preparación de \n",
      "características...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Primer_modelo_entrenado.pdf:\n",
      "Hoja informativa: Primer modelo entrenado\n",
      "1\n",
      "Hoja informativa: Primer modelo \n",
      "entrenado\n",
      "Práctica\n",
      "# Ob...\n",
      "\n",
      "Texto extraído de moved_Hoja_informativa_Relaciones_entre_tablas.pdf:\n",
      "Hoja informativa: Relaciones entre tablas\n",
      "1\n",
      "Hoja informativa: Relaciones \n",
      "entre tablas\n",
      "Práctica\n",
      "-- S...\n",
      "\n",
      "Texto extraído de moved_Resumen_del_captulo_Calidad_del_modelo.pdf:\n",
      "Resumen del capítulo: Calidad del modelo\n",
      "1\n",
      "Resumen del capítulo: Calidad \n",
      "del modelo\n",
      "Aleatoriedad en...\n",
      "\n",
      "Texto extraído de moved_Resumen_del_captulo_clasificacin_desequilibrad.pdf:\n",
      "Resumen del capítulo: clasificación desequilibrada\n",
      "1\n",
      "Resumen del capítulo: \n",
      "clasificación desequilib...\n",
      "\n",
      "Texto extraído de moved_Resumen_del_captulo_Implementacin_de_nuevas_funciones.pdf:\n",
      "Resumen del capítulo: Implementación de nuevas funciones\n",
      "1\n",
      "Resumen del capítulo: Implementación \n",
      "de ...\n",
      "\n",
      "Texto extraído de moved_Resumen_del_captulo_Mejora_del_modelo.pdf:\n",
      "Resumen del capítulo: Mejora del modelo\n",
      "1\n",
      "Resumen del capítulo: Mejora del \n",
      "modelo\n",
      "Datasets de valid...\n",
      "\n",
      "Texto extraído de moved_Resumen_del_captulo_Pasar_a_la_regresin.pdf:\n",
      "Resumen del capítulo: Pasar a la regresión\n",
      "1\n",
      "Resumen del capítulo: Pasar a la \n",
      "regresión\n",
      "Error cuadr...\n",
      "\n",
      "Texto extraído de moved_Resumen_del_captulo_preparacin_de_caractersticas.pdf:\n",
      "Resumen del capítulo: preparación de características\n",
      "1\n",
      "Resumen del capítulo: \n",
      "preparación de caracte...\n",
      "\n",
      "Texto extraído de moved_Resumen_del_captulo_Primer_modelo_entrenado.pdf:\n",
      "Resumen del capítulo: Primer modelo entrenado\n",
      "1\n",
      "Resumen del capítulo: Primer \n",
      "modelo entrenado\n",
      "Datas...\n",
      "\n",
      "Texto extraído de Resumen_del_capitulo_metricas_de_regresion.pdf:\n",
      "Resumen del capítulo: métricas de regresión\n",
      "1\n",
      "Resumen del capítulo: métricas \n",
      "de regresión\n",
      "Coeficien...\n",
      "\n",
      "Texto extraído de Resumen_del_capítulo_Entrenamiento_del_descenso.pdf:\n",
      "Resumen del capítulo: Entrenamiento del descenso de gradiente\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Entrenamiento...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Anlisis_de_algoritmos.pdf:\n",
      "Resumen del capítulo: Análisis de algoritmos\n",
      "1\n",
      "Resumen del capítulo: Análisis \n",
      "de algoritmos\n",
      "Complej...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Descenso_de_gradiente.pdf:\n",
      "Resumen del capítulo: Descenso de gradiente\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Descenso de gradiente\n",
      "Minimizac...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Distancia_entre_vectores.pdf:\n",
      "Resumen del capítulo: Distancia entre vectores\n",
      "1\n",
      "Resumen del capítulo: Distancia \n",
      "entre vectores\n",
      "Pro...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Funciones_avanzadas_de_SQL_para_analistas.pdf:\n",
      "Resumen del capítulo: Funciones avanzadas de SQL para analistas\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Funciones a...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Ingeniera_de_caractersticas.pdf:\n",
      "Resumen del capítulo: Ingeniería de características\n",
      "1\n",
      "Resumen del capítulo: Ingeniería \n",
      "de caracterí...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Matrices_y_operaciones_matriciales.pdf:\n",
      "Resumen del capítulo: Matrices y operaciones matriciales\n",
      "1\n",
      "Resumen del capítulo: Matrices y \n",
      "operaci...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_metricas_de_clasificacion.pdf:\n",
      "Resumen del capítulo: métricas de clasificación\n",
      "1\n",
      "Resumen del capítulo: métricas \n",
      "de clasificación\n",
      "E...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Potenciacin_del_gradiente.pdf:\n",
      "Resumen del capítulo: Potenciación del gradiente\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Potenciación del gradiente...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Pronstico_de_series_temporales.pdf:\n",
      "Resumen del capítulo: Pronóstico de series temporales\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Pronóstico de series ...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Recuperacin_de_datos_de_recursos_en_lnea.pdf:\n",
      "Resumen del capítulo: Recuperación de datos de recursos en línea\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Recuperaci...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Redes_neuronales_convolucionales_esp.pdf:\n",
      "Resumen del capítulo: Redes neuronales convolucionales\n",
      "1\n",
      "Resumen del capítulo: Redes \n",
      "neuronales con...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Redes_totalmente_conectadas.pdf:\n",
      "Resumen del capítulo: Redes totalmente conectadas\n",
      "1\n",
      "Resumen del capítulo: Redes \n",
      "totalmente conectad...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Regresin_lineal_desde_adentro.pdf:\n",
      "Resumen del capítulo: Regresión lineal desde adentro\n",
      "1\n",
      "Resumen del capítulo: Regresión \n",
      "lineal desde...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Relaciones_entre_tablas.pdf:\n",
      "Resumen del capítulo: Relaciones entre tablas\n",
      "1\n",
      "Resumen del capítulo: \n",
      "Relaciones entre tablas\n",
      "Tipos...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_SQL_como_herramienta_para_trabajar_con_datos.pdf:\n",
      "Resumen del capítulo: SQL como herramienta para trabajar con datos\n",
      "1\n",
      "Resumen del capítulo: SQL \n",
      "como...\n",
      "\n",
      "Texto extraído de Resumen_del_captulo_Vectores_y_operaciones_vectoriales.pdf:\n",
      "Resumen del capítulo: Vectores y operaciones vectoriales\n",
      "1\n",
      "Resumen del capítulo: Vectores \n",
      "y operaci...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carpeta_pdfs = \"ds_pdf\"\n",
    "textos_por_archivo = extraer_texto_de_pdfs(carpeta_pdfs)\n",
    "for nombre, texto in textos_por_archivo.items():\n",
    "    print(f\"Texto extraído de {nombre}:\\n{texto[:100]}...\\n\")  # Muestra los primeros 100 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20df8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"todo_el_texto.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for nombre, texto in textos_por_archivo.items():\n",
    "        f.write(f\"\\n### {nombre} ###\\n\")\n",
    "        f.write(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "284bd5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documento': '1._fundamentos_de_hojas_de_clculo.pdf', 'id': '1._fundamentos_de_hojas_de_clculo.pdf_chunk0', 'texto': '1. Fundamentos de hojas de cálculo\\n1\\n1. Fundamentos de hojas de \\ncálculo\\n1.1 Cómo acceder a los datos de una hoja de cálculo\\nFormatos comunes de archivos de hojas de cálculo\\n.xlsx  (Excel): adecuado para análisis de datos complejos con funciones \\nde fórmulas, gráficos y distintas opciones de formato.\\n.csv  (es decir, \"comma-separated values\" o valores separados por \\ncomas): formato simplificado, solo texto, ideal para la representación \\ntabular de datos y una amplia compatibilidad de programas.'}\n"
     ]
    }
   ],
   "source": [
    "def dividir_en_fragmentos(texto, largo=500, solapamiento=100):\n",
    "    fragmentos = []\n",
    "    inicio = 0\n",
    "    while inicio < len(texto):\n",
    "        fin = inicio + largo\n",
    "        fragmento = texto[inicio:fin]\n",
    "        fragmentos.append(fragmento.strip())\n",
    "        inicio += largo - solapamiento\n",
    "    return fragmentos\n",
    "\n",
    "# Aplicación a todos los textos\n",
    "todos_los_fragmentos = []\n",
    "for nombre_pdf, texto in textos_por_archivo.items():\n",
    "    partes = dividir_en_fragmentos(texto)\n",
    "    for i, fragmento in enumerate(partes):\n",
    "        todos_los_fragmentos.append({\n",
    "            \"documento\": nombre_pdf,\n",
    "            \"id\": f\"{nombre_pdf}_chunk{i}\",\n",
    "            \"texto\": fragmento\n",
    "        })\n",
    "\n",
    "# Ejemplo de uno\n",
    "print(todos_los_fragmentos[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a006d41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a9cf6b4c124f6783a7ef76ab86e026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar el modelo\n",
    "modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Extraer los textos\n",
    "textos = [f[\"texto\"] for f in todos_los_fragmentos]\n",
    "\n",
    "# Crear embeddings\n",
    "embeddings = modelo.encode(textos, show_progress_bar=True)\n",
    "\n",
    "# Crear el índice FAISS\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# Guardar el índice y los metadatos\n",
    "faiss.write_index(index, \"indice_faiss.index\")\n",
    "\n",
    "with open(\"fragmentos.pkl\", \"wb\") as f:\n",
    "    pickle.dump(todos_los_fragmentos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc6af4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo, índice y fragmentos\n",
    "modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "index = faiss.read_index(\"indice_faiss.index\")\n",
    "with open(\"fragmentos.pkl\", \"rb\") as f:\n",
    "    fragmentos = pickle.load(f)\n",
    "\n",
    "def buscar_contexto(pregunta, top_k=3):\n",
    "    embedding_pregunta = modelo.encode([pregunta])\n",
    "    distancias, indices = index.search(np.array(embedding_pregunta), top_k)\n",
    "\n",
    "    resultados = []\n",
    "    for i in indices[0]:\n",
    "        resultados.append(fragmentos[i])\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5407ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 ESP_Resumen_del_captulo_Vectorizacin_de_textos.pdf:\n",
      "ub(r'[^a-zA-Z\\']', ' ', text) \n",
      "\" Me gustó este programa desde el primer episodio que vi que fue el  episodio  Rhapsody in \n",
      "Blue  para quienes no saben qué es  el Zan se vuelve loco y se convierte en pau episodio n\n",
      "ivel    10   Los mejores efectos visuales y especiales que había visto en una serie de tel\n",
      "evisión no hay nada parecido en ninguna parte  \" \n",
      "Ahora no nos quedan más que las letras latinas y los espacios. En el siguiente paso, \n",
      "vamos a deshacernos de los espacios extra, ya que dificulta\n",
      "\n",
      "📄 1_Resumen_del_captulo_Lectura_y_visualizacin_de_datos.pdf:\n",
      "Resumen del capítulo: Lectura y visualización de datos\n",
      "1\n",
      "Resumen del capítulo: Lectura y \n",
      "visualización de datos\n",
      "Solucionar problemas con archivos CSV\n",
      "Recuerda que CSV significa valores separados por comas. Sin embargo, un archivo \n",
      "CSV no tiene que usar solo una coma como delimitador; se puede usar cualquier \n",
      "carácter. Por ejemplo, los valores separados por tabuladores son otro formato común.\n",
      "Puedes cambiar el delimitador utilizando el parámetro sep= . También puedes \n",
      "establecer los nombres de l\n",
      "\n",
      "📄 1._fundamentos_de_hojas_de_clculo.pdf:\n",
      "l momento de \n",
      "importar asegúrate de seleccionar \"Coma\" como el tipo de separador para \n",
      "que tus datos tengan el formato correcto.\n",
      "Cómo guardar Google Sheets como archivos de Excel o CSV\n",
      "Utiliza \"Archivo > Descargar\" para guardar tus datos en diferentes \n",
      "formatos.\n",
      "La selección entre los formatos de Excel y CSV depende de las \n",
      "necesidades específicas del usuario para la complejidad de los datos y su \n",
      "intercambio.\n",
      "1.2 Estructura de las hojas de cálculo\n",
      "Conceptos básicos:\n",
      "Fila. Línea de datos horizon\n"
     ]
    }
   ],
   "source": [
    "resultados = buscar_contexto(\"¿Qué es un archivo CSV?\")\n",
    "\n",
    "for r in resultados:\n",
    "    print(f\"\\n📄 {r['documento']}:\\n{r['texto'][:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ad30cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb48c7232c0f4ba4a27050a0fe1a449b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lalox\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lalox\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03cf0982c2e4dc9b1cf0e0a9ef66cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af43e3ac618e46cd88c4570ab5c724e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a24847d495b42ef973c465dc1cc3ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60268ed5c3c84fefbf92e58a2eb2f42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3350b495b04a4f800b61a06d42a4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efcb2aa01a049f7979acadd982d9310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Cargar modelo y tokenizer\n",
    "modelo_id = \"gpt2\"  # modelo público pequeño para pruebas\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_id)\n",
    "modelo = AutoModelForCausalLM.from_pretrained(modelo_id)\n",
    "\n",
    "def responder_con_contexto(pregunta, fragmentos, max_tokens=512):\n",
    "    # Juntar los fragmentos en un solo bloque de texto\n",
    "    contexto = \"\\n\".join([f\"- {frag['texto']}\" for frag in fragmentos])\n",
    "\n",
    "    prompt = f\"\"\"Usa el siguiente contexto para responder la pregunta del usuario de forma clara y precisa.\n",
    "\n",
    "Contexto:\n",
    "{contexto}\n",
    "\n",
    "Pregunta: {pregunta}\n",
    "Respuesta:\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_tokens)\n",
    "    outputs = modelo.generate(**inputs, max_new_tokens=200, do_sample=True, temperature=0.7)\n",
    "\n",
    "    respuesta = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extraer solo la parte de la respuesta\n",
    "    return respuesta.split(\"Respuesta:\")[-1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ab4b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2LMHeadModel' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fragmentos \u001b[38;5;241m=\u001b[39m \u001b[43mbuscar_contexto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m¿Qué es un archivo CSV?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m respuesta \u001b[38;5;241m=\u001b[39m responder_con_contexto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m¿Qué es un archivo CSV?\u001b[39m\u001b[38;5;124m\"\u001b[39m, fragmentos)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🤖 Asistente responde:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, respuesta)\n",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m, in \u001b[0;36mbuscar_contexto\u001b[1;34m(pregunta, top_k)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuscar_contexto\u001b[39m(pregunta, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     embedding_pregunta \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m([pregunta])\n\u001b[0;32m      9\u001b[0m     distancias, indices \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39msearch(np\u001b[38;5;241m.\u001b[39marray(embedding_pregunta), top_k)\n\u001b[0;32m     11\u001b[0m     resultados \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\lalox\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1940\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1938\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1939\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1940\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1942\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GPT2LMHeadModel' object has no attribute 'encode'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faddd6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta del modelo:\n",
      " - El preprocesamiento de datos incluye limpieza a las máquinas aprender de los datos.\n",
      "\n",
      "- El preprocesamiento de datos incluye limpieza a las máquinas aprender de los datos.\n",
      "\n",
      "- El preprocesamiento de datos incluye limpieza a las máquinas aprender de los datos.\n",
      "\n",
      "- El preprocesamiento de datos incluye limpieza a las máquinas aprender de los datos.\n",
      "\n",
      "- El preprocesamiento de datos incluye limpieza a las máquinas aprender de los datos.\n",
      "\n",
      "- El preprocesamiento de datos incluye limpieza a las máquinas aprender de los datos.\n",
      "\n",
      "- El preprocesam\n"
     ]
    }
   ],
   "source": [
    "fragmentos = [\n",
    "    {\"texto\": \"El aprendizaje automático es una rama de la inteligencia artificial que permite a las máquinas aprender de los datos.\"},\n",
    "    {\"texto\": \"El preprocesamiento de datos incluye limpieza, transformación y normalización para mejorar los resultados.\"}\n",
    "]\n",
    "\n",
    "\n",
    "pregunta = \"¿Qué es el aprendizaje automático?\"\n",
    "respuesta = responder_con_contexto(pregunta, fragmentos)\n",
    "print(\"Respuesta del modelo:\\n\", respuesta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242678da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
